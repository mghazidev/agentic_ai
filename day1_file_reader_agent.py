from langchain_ollama import OllamaLLM
from langchain_community.document_loaders import TextLoader
from langchain_core.prompts import PromptTemplate

# =========================
# 1Ô∏è‚É£ LOAD LLM (Brain)
# =========================
llm = OllamaLLM(model="llama3")

# =========================
# 2Ô∏è‚É£ LOAD FILE
# =========================
loader = TextLoader("restaurants.txt")
documents = loader.load()
restaurant_data = documents[0].page_content

# =========================
# 3Ô∏è‚É£ PROMPT TEMPLATE
# =========================
prompt = PromptTemplate(
    input_variables=["data", "question"],
    template="""
You are a food data analyst.
Here is restaurant data:
{data}

Answer the following question clearly and accurately:
{question}
"""
)

# =========================
# 4Ô∏è‚É£ CHAIN (Modern LCEL Style)
# =========================
chain = prompt | llm

# =========================
# 5Ô∏è‚É£ ASK QUESTIONS
# =========================
while True:
    question = input("\nAsk a question (or type 'exit'): ")
    if question.lower() == "exit":
        break
    
    response = chain.invoke({
        "data": restaurant_data,
        "question": question
    })
    print("\nüçΩÔ∏è Answer:\n", response)